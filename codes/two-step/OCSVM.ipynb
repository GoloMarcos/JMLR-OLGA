{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Validation"
      ],
      "metadata": {
        "id": "InFBqe9B2kjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install networkx==2.6"
      ],
      "metadata": {
        "id": "CEnjdPNKhduZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud9784xY-tpB"
      },
      "outputs": [],
      "source": [
        "from pandas.core.base import value_counts\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.svm import OneClassSVM as OCSVM\n",
        "\n",
        "def define_gammas():\n",
        "  gammas = ['scale', 'auto']\n",
        "  return gammas\n",
        "\n",
        "def define_nus():\n",
        "  nus = []\n",
        "  for n in range(5,90,5):\n",
        "    nus.append(n/100)\n",
        "  for n in range(5,90,5):\n",
        "    nus.append(n/1000)\n",
        "\n",
        "  return nus\n",
        "\n",
        "def define_kernels():\n",
        "  return ['rbf', 'sigmoid','linear', 'poly']\n",
        "\n",
        "def evaluation_one_class(preds_interest, preds_outliers):\n",
        "    y_true = [1] * len(preds_interest) + [-1] * len(preds_outliers)\n",
        "    y_pred = list(preds_interest) + list(preds_outliers)\n",
        "    return classification_report(y_true, y_pred, output_dict=True)\n",
        "\n",
        "def evaluate_model(X_train, X_test, X_outlier, model):\n",
        "\n",
        "    one_class_classifier = model.fit(X_train)\n",
        "\n",
        "    Y_pred_interest = one_class_classifier.predict(X_test)\n",
        "\n",
        "    Y_pred_ruido = one_class_classifier.predict(X_outlier)\n",
        "\n",
        "    y_true = np.array([1] * len(X_test) + [-1] * len(X_outlier))\n",
        "\n",
        "    dic = evaluation_one_class(Y_pred_interest, Y_pred_ruido)\n",
        "\n",
        "    return dic\n",
        "\n",
        "def init_metrics():\n",
        "    metrics = {\n",
        "        '1': {\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1-score': []\n",
        "        },\n",
        "        '-1': {\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1-score': []\n",
        "        },\n",
        "        'macro avg': {\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1-score': []\n",
        "        },\n",
        "        'weighted avg': {\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1-score': []\n",
        "        },\n",
        "        'accuracy': [],\n",
        "        'time': []\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def save_values(metrics, values):\n",
        "    for key in metrics.keys():\n",
        "      if key == 'accuracy' or key == 'time':\n",
        "        metrics[key].append(values[key])\n",
        "      else:\n",
        "        for key2 in metrics[key].keys():\n",
        "          metrics[key][key2].append(values[key][key2])\n",
        "\n",
        "\n",
        "def extract_emb_from_graph(graph, representation_name):\n",
        "\n",
        "  x_train, x_int_val, x_nint_val, x_int_test, x_nint_test = [],[],[],[],[]\n",
        "\n",
        "  for node in graph.nodes():\n",
        "    if graph.nodes[node]['train'] == 1:\n",
        "      x_train.append(graph.nodes[node][representation_name])\n",
        "    elif graph.nodes[node]['val'] == 1 and graph.nodes[node]['label'] == 1:\n",
        "      x_int_val.append(graph.nodes[node][representation_name])\n",
        "    elif graph.nodes[node]['val'] == 1 and graph.nodes[node]['label'] == 0:\n",
        "      x_nint_val.append(graph.nodes[node][representation_name])\n",
        "    elif graph.nodes[node]['test'] == 1 and graph.nodes[node]['label'] == 1:\n",
        "      x_int_test.append(graph.nodes[node][representation_name])\n",
        "    elif graph.nodes[node]['test'] == 1 and graph.nodes[node]['label'] == 0:\n",
        "      x_nint_test.append(graph.nodes[node][representation_name])\n",
        "\n",
        "  return x_train, x_int_val, x_nint_val, x_int_test, x_nint_test\n",
        "\n",
        "def evaluate_models(l_graphs, representation_name, path, fn):\n",
        "\n",
        "    file_name = fn + representation_name + '_OCSVM.csv'\n",
        "\n",
        "    for kernel in define_kernels():\n",
        "      for gamma in define_gammas():\n",
        "        for nu in define_nus():\n",
        "          ocsvm = OCSVM(kernel=kernel,nu=nu,gamma=gamma)\n",
        "          line_parameters =  'kernel:' + kernel + '_gamma:' + gamma + '_nu:' + str(nu)\n",
        "          metrics = init_metrics()\n",
        "\n",
        "          for graph in l_graphs:\n",
        "\n",
        "            x_train,x_int_val,x_nint_val,x_int_test,x_nint_test = extract_emb_from_graph(graph, representation_name)\n",
        "\n",
        "            start = time.time()\n",
        "            values = evaluate_model(x_train, x_int_val, x_nint_val, ocsvm)\n",
        "            end = time.time()\n",
        "            time_ = end - start\n",
        "            values['time'] = time_\n",
        "            save_values(metrics, values)\n",
        "\n",
        "          write_results(metrics, file_name, line_parameters, path)\n",
        "\n",
        "\n",
        "def write_results(metrics, file_name, line_parameters, path):\n",
        "    if not Path(path + file_name).is_file():\n",
        "        file_ = open(path + file_name, 'w')\n",
        "        string = 'Parameters'\n",
        "        for key in metrics.keys():\n",
        "            if key == 'accuracy' or key == 'time':\n",
        "              string += ';' + key + '-mean;' + key + '-std'\n",
        "            else:\n",
        "              for key2 in metrics[key].keys():\n",
        "                string += ';' + key + '_' + key2 + '-mean;' + key + '_' + key2 + '-std'\n",
        "\n",
        "        string += '\\n'\n",
        "        file_.write(string)\n",
        "        file_.close()\n",
        "\n",
        "    file_ = open(path + file_name, 'a')\n",
        "    string = line_parameters\n",
        "\n",
        "    for key in metrics.keys():\n",
        "      if key == 'accuracy' or key == 'time':\n",
        "        string += ';' + str(np.mean(metrics[key])) + ';' + str(np.std(metrics[key]))\n",
        "      else:\n",
        "        for key2 in metrics[key].keys():\n",
        "          string += ';' + str(np.mean(metrics[key][key2])) + ';' + str(np.std(metrics[key][key2]))\n",
        "\n",
        "    string += '\\n'\n",
        "    file_.write(string)\n",
        "    file_.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNinuYz-9c95"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pt = '/content/drive/MyDrive/USP/Doctorate/Research/Articles/OLGA: One cLass Graph Autoencoder/datasets/graphs/'\n",
        "\n",
        "basepath = Path(pt)\n",
        "\n",
        "path_results = '/content/drive/MyDrive/USP/Doctorate/Research/Articles/OLGA: One cLass Graph Autoencoder/results/\n",
        "\n",
        "datasets = basepath.iterdir()\n",
        "\n",
        "for dataset in ['fakenews', 'terrorism', 'relevant_reviews', 'food', 'strawberry', 'pneumonia', 'musk', 'TUANDROMD']:\n",
        "  print('no dataset: ' + dataset)\n",
        "  for k in ['k=1', 'k=2', 'k=3']:\n",
        "    print('no k: ' + k)\n",
        "    l_graphs = []\n",
        "    for fold in range(10):\n",
        "      path = pt + dataset + '/' + k + '/' + dataset + '_' + k + '_fold=' + str(fold) + '.gpickle'\n",
        "\n",
        "      graph = nx.read_gpickle(path)\n",
        "      l_graphs.append(graph)\n",
        "\n",
        "    for rep_initial in ['features_node2vec', 'features_deepwalk', 'features_gae','features_node2vec_3', 'features_deepwalk_3', 'features_gae_3', 'features_gae_2', 'features_deepwalk_2', 'features_node2vec_2']:\n",
        "\n",
        "      print('com rep: ' + rep_initial)\n",
        "      evaluate_models(l_graphs, rep_initial, path_results, dataset + '_' + k + '_')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "LN6JP7Bu2oxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_results = '/content/drive/MyDrive/USP/Doctorate/Research/Articles/OLGA: One cLass Graph Autoencoder/results/'\n",
        "\n",
        "path_results_test = '/content/drive/MyDrive/USP/Doctorate/Research/Articles/OLGA: One cLass Graph Autoencoder/results_test/'\n",
        "\n",
        "pt = '/content/drive/MyDrive/USP/Doctorate/Research/Articles/OLGA: One cLass Graph Autoencoder/datasets/graphs/'\n",
        "\n",
        "basepath = Path(path_results)\n",
        "datasets = basepath.iterdir()\n",
        "\n",
        "for dataset in datasets:\n",
        "  dataset = dataset.name\n",
        "  print('Dataset: ' + dataset)\n",
        "  basepath2 = Path(path_results + dataset)\n",
        "  ks = basepath2.iterdir()\n",
        "\n",
        "  for k in ks:\n",
        "    k = k.name\n",
        "    print('K: ' + k)\n",
        "    basepath3 = Path(path_results + dataset + '/' + k)\n",
        "    methods = basepath3.iterdir()\n",
        "\n",
        "    l_graphs = []\n",
        "    for fold in range(10):\n",
        "      path = pt + dataset + '/' + k + '/' + dataset + '_' + k + '_fold=' + str(fold) + '.gpickle'\n",
        "\n",
        "      graph = nx.read_gpickle(path)\n",
        "      l_graphs.append(graph)\n",
        "\n",
        "    pr = path_results_test + dataset + '_' + k + '_'\n",
        "\n",
        "    for method in methods:\n",
        "      if method.is_file() and method.name.split('-')[0] != 'OC':\n",
        "\n",
        "        method = method.name\n",
        "        df = pd.read_csv(path_results + dataset + '_' + k + '_' + method, sep=';')\n",
        "\n",
        "        best_f1 = max(df['macro avg_f1-score-mean'])\n",
        "\n",
        "        parameters = df[df['macro avg_f1-score-mean'] == best_f1]['Parameters'].iloc[0]\n",
        "\n",
        "        parts = parameters.split('_')\n",
        "\n",
        "        kernel = parts[0].split(':')[1]\n",
        "\n",
        "        gamma = parts[1].split(':')[1]\n",
        "\n",
        "        nu = float(parts[2].split(':')[1])\n",
        "\n",
        "        ocsvm = OCSVM(kernel=kernel,nu=nu,gamma=gamma)\n",
        "        line_parameters =  'kernel:' + kernel + '_gamma:' + gamma + '_nu:' + str(nu)\n",
        "        metrics = init_metrics()\n",
        "\n",
        "        for graph in l_graphs:\n",
        "\n",
        "          x_train, x_int_val, _, x_int_test, x_nint_test = extract_emb_from_graph(graph, method.replace('_OCSVM.csv', ''))\n",
        "\n",
        "          x_train = np.concatenate([x_train,x_int_val])\n",
        "\n",
        "          start = time.time()\n",
        "          values = evaluate_model(x_train, x_int_test, x_nint_test, ocsvm)\n",
        "          end = time.time()\n",
        "          time_ = end - start\n",
        "          values['time'] = time_\n",
        "          save_values(metrics, values)\n",
        "\n",
        "        write_results(metrics, method, line_parameters, pr)"
      ],
      "metadata": {
        "id": "QPa_ynNN2xit"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}